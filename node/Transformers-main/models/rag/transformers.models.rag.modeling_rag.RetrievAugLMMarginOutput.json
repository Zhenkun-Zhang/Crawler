{
    "api": "transformers.models.rag.modeling_rag.RetrievAugLMMarginOutput",
    "type": "class",
    "version": "main",
    "args_list": [
        "loss:",
        "logits",
        "doc_scores",
        "past_key_values",
        "retrieved_doc_embeds",
        "retrieved_doc_ids",
        "context_input_ids",
        "context_attention_mask",
        "question_encoder_last_hidden_state",
        "question_enc_hidden_states",
        "...]]",
        "question_enc_attentions",
        "...]]",
        "generator_enc_last_hidden_state",
        "generator_enc_hidden_states",
        "...]]",
        "generator_enc_attentions",
        "...]]",
        "generator_dec_hidden_states",
        "...]]",
        "generator_dec_attentions",
        "...]]",
        "generator_cross_attentions",
        "...]]"
    ],
    "params": [
        {
            "name": "loss",
            "type": "torch.FloatTensor of shape (1,",
            "optional": true,
            "default": "",
            "description": "Language modeling loss."
        },
        {
            "name": "logits",
            "type": "torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size)",
            "optional": false,
            "default": "",
            "description": "Prediction scores of the language modeling head. The score is possibly marginalized over all documents foreach vocabulary token."
        },
        {
            "name": "doc_scores",
            "type": "torch.FloatTensor of shape (batch_size, config.n_docs)",
            "optional": false,
            "default": "",
            "description": "Score between each retrieved document embeddings (see retrieved_doc_embeds) andquestion_encoder_last_hidden_state."
        },
        {
            "name": "past_key_values",
            "type": "List[torch.FloatTensor]",
            "optional": true,
            "default": "",
            "description": "List of torch.FloatTensor of length config.n_layers, with each tensor of shape (2, batch_size, num_heads, sequence_length, embed_size_per_head)).Contains precomputed hidden-states (key and values in the attention blocks) of the decoder that can be used(see past_key_values input) to speed up sequential decoding."
        },
        {
            "name": "retrieved_doc_embeds",
            "type": "torch.FloatTensor of shape (batch_size, config.n_docs, hidden_size",
            "optional": true,
            "default": "",
            "description": "Embedded documents retrieved by the retriever. Is used with question_encoder_last_hidden_state to computethe doc_scores."
        },
        {
            "name": "retrieved_doc_ids",
            "type": "torch.LongTensor of shape (batch_size, config.n_docs",
            "optional": true,
            "default": "",
            "description": "The indexes of the embedded documents retrieved by the retriever."
        },
        {
            "name": "context_input_ids",
            "type": "torch.LongTensor of shape (batch_size * config.n_docs, config.max_combined_length",
            "optional": true,
            "default": "",
            "description": "Input ids post-processed from the retrieved documents and the question encoder input_ids by the retriever."
        },
        {
            "name": "context_attention_mask",
            "type": "torch.LongTensor of shape (batch_size * config.n_docs, config.max_combined_length",
            "optional": true,
            "default": "",
            "description": "Attention mask post-processed from the retrieved documents and the question encoder input_ids by theretriever."
        },
        {
            "name": "question_encoder_last_hidden_state",
            "type": "torch.FloatTensor of shape (batch_size, sequence_length, hidden_size",
            "optional": true,
            "default": "",
            "description": "Sequence of hidden states at the output of the last layer of the question encoder pooled output of themodel."
        },
        {
            "name": "question_enc_hidden_states",
            "type": "tuple(torch.FloatTensor",
            "optional": true,
            "default": "",
            "description": "Tuple of torch.FloatTensor (one for the output of the embeddings and one for the output of each layer) ofshape (batch_size, sequence_length, hidden_size).Hidden states of the question encoder at the output of each layer plus the initial embedding outputs."
        },
        {
            "name": "question_enc_attentions",
            "type": "tuple(torch.FloatTensor",
            "optional": true,
            "default": "",
            "description": "Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).Attentions weights of the question encoder, after the attention softmax, used to compute the weightedaverage in the self-attention heads."
        },
        {
            "name": "generator_enc_last_hidden_state",
            "type": "torch.FloatTensor of shape (batch_size, sequence_length, hidden_size",
            "optional": true,
            "default": "",
            "description": "Sequence of hidden-states at the output of the last layer of the generator encoder of the model."
        },
        {
            "name": "generator_enc_hidden_states",
            "type": "tuple(torch.FloatTensor",
            "optional": true,
            "default": "",
            "description": "Tuple of torch.FloatTensor (one for the output of the embeddings and one for the output of each layer) ofshape (batch_size, sequence_length, hidden_size).Hidden states of the generator encoder at the output of each layer plus the initial embedding outputs."
        },
        {
            "name": "generator_enc_attentions",
            "type": "tuple(torch.FloatTensor",
            "optional": true,
            "default": "",
            "description": "Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).Attentions weights of the generator encoder, after the attention softmax, used to compute the weightedaverage in the self-attention heads."
        },
        {
            "name": "generator_dec_hidden_states",
            "type": "tuple(torch.FloatTensor",
            "optional": true,
            "default": "",
            "description": "Tuple of torch.FloatTensor (one for the output of the embeddings and one for the output of each layer) ofshape (batch_size, sequence_length, hidden_size).Hidden states of the generator decoder at the output of each layer plus the initial embedding outputs."
        },
        {
            "name": "generator_dec_attentions",
            "type": "tuple(torch.FloatTensor",
            "optional": true,
            "default": "",
            "description": "Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).Attentions weights of the generator decoder, after the attention softmax, used to compute the weightedaverage in the self-attention heads."
        },
        {
            "name": "generator_cross_attentions",
            "type": "tuple(torch.FloatTensor",
            "optional": true,
            "default": "",
            "description": "Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).Cross-attentions weights of the generator decoder, after the attention softmax, used to compute theweighted average in the cross-attention heads."
        }
    ],
    "return": ""
}