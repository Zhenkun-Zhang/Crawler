{
    "api": "transformers.MLukeTokenizer.__call__",
    "type": "function",
    "version": "main",
    "args_list": [
        "text:",
        "typing.List[str]]",
        "text_pair",
        "typing.List[str],",
        "NoneType]",
        "entity_spans",
        "int]],",
        "typing.List[typing.List[typing.Tuple[int,",
        "int]]],",
        "NoneType]",
        "entity_spans_pair",
        "int]],",
        "typing.List[typing.List[typing.Tuple[int,",
        "int]]],",
        "NoneType]",
        "entities",
        "typing.List[typing.List[str]],",
        "NoneType]",
        "entities_pair",
        "typing.List[typing.List[str]],",
        "NoneType]",
        "add_special_tokens",
        "padding",
        "str,",
        "transformers.utils.generic.PaddingStrategy]",
        "truncation",
        "str,",
        "transformers.tokenization_utils_base.TruncationStrategy]",
        "max_length",
        "max_entity_length",
        "stride",
        "is_split_into_words",
        "pad_to_multiple_of",
        "padding_side",
        "return_tensors",
        "transformers.utils.generic.TensorType,",
        "NoneType]",
        "return_token_type_ids",
        "return_attention_mask",
        "return_overflowing_tokens",
        "return_special_tokens_mask",
        "return_offsets_mapping",
        "return_length",
        "verbose",
        "**kwargs",
        ")"
    ],
    "params": [
        {
            "name": "text",
            "type": "str, List[str], List[List[str]]",
            "optional": false,
            "default": "",
            "description": "The sequence or batch of sequences to be encoded. Each sequence must be a string. Note that thistokenizer does not support tokenization based on pretokenized strings."
        },
        {
            "name": "text_pair",
            "type": "str, List[str], List[List[str]]",
            "optional": false,
            "default": "",
            "description": "The sequence or batch of sequences to be encoded. Each sequence must be a string. Note that thistokenizer does not support tokenization based on pretokenized strings."
        },
        {
            "name": "entity_spans",
            "type": "List[Tuple[int, int]], List[List[Tuple[int, int]]]",
            "optional": true,
            "default": "",
            "description": "The sequence or batch of sequences of entity spans to be encoded. Each sequence consists of tuples eachwith two integers denoting character-based start and end positions of entities. If you specifyentity_classification or entity_pair_classification as the task argument in the constructor,the length of each sequence must be 1 or 2, respectively. If you specify entities, the length of eachsequence must be equal to the length of each sequence of entities."
        },
        {
            "name": "entity_spans_pair",
            "type": "List[Tuple[int, int]], List[List[Tuple[int, int]]]",
            "optional": true,
            "default": "",
            "description": "The sequence or batch of sequences of entity spans to be encoded. Each sequence consists of tuples eachwith two integers denoting character-based start and end positions of entities. If you specify thetask argument in the constructor, this argument is ignored. If you specify entities_pair, thelength of each sequence must be equal to the length of each sequence of entities_pair."
        },
        {
            "name": "entities",
            "type": "List[str], List[List[str]]",
            "optional": true,
            "default": "",
            "description": "The sequence or batch of sequences of entities to be encoded. Each sequence consists of stringsrepresenting entities, i.e., special entities (e.g., [MASK]) or entity titles of Wikipedia (e.g., LosAngeles). This argument is ignored if you specify the task argument in the constructor. The length ofeach sequence must be equal to the length of each sequence of entity_spans. If you specifyentity_spans without specifying this argument, the entity sequence or the batch of entity sequencesis automatically constructed by filling it with the [MASK] entity."
        },
        {
            "name": "entities_pair",
            "type": "List[str], List[List[str]]",
            "optional": true,
            "default": "",
            "description": "The sequence or batch of sequences of entities to be encoded. Each sequence consists of stringsrepresenting entities, i.e., special entities (e.g., [MASK]) or entity titles of Wikipedia (e.g., LosAngeles). This argument is ignored if you specify the task argument in the constructor. The length ofeach sequence must be equal to the length of each sequence of entity_spans_pair. If you specifyentity_spans_pair without specifying this argument, the entity sequence or the batch of entitysequences is automatically constructed by filling it with the [MASK] entity."
        },
        {
            "name": "max_entity_length",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "The maximum length of entity_ids."
        },
        {
            "name": "add_special_tokens",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to add special tokens when encoding the sequences. This will use the underlyingPretrainedTokenizerBase.build_inputs_with_special_tokens function, which defines which tokens areautomatically added to the input ids. This is useful if you want to add bos or eos tokensautomatically."
        },
        {
            "name": "padding",
            "type": "bool, str,PaddingStrategy",
            "optional": true,
            "default": "",
            "description": "Activates and controls padding. Accepts the following values:True or longest: Pad to the longest sequence in the batch (or no padding if only a singlesequence if provided).max_length: Pad to a maximum length specified with the argument max_length or to the maximumacceptable input length for the model if that argument is not provided.False or do_not_pad (default): No padding (i.e., can output a batch with sequences of differentlengths)."
        },
        {
            "name": "truncation",
            "type": "bool, str,TruncationStrategy",
            "optional": true,
            "default": "",
            "description": "Activates and controls truncation. Accepts the following values:True or longest_first: Truncate to a maximum length specified with the argument max_length orto the maximum acceptable input length for the model if that argument is not provided. This willtruncate token by token, removing a token from the longest sequence in the pair if a pair ofsequences (or a batch of pairs) is provided.only_first: Truncate to a maximum length specified with the argument max_length or to themaximum acceptable input length for the model if that argument is not provided. This will onlytruncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.only_second: Truncate to a maximum length specified with the argument max_length or to themaximum acceptable input length for the model if that argument is not provided. This will onlytruncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.False or do_not_truncate (default): No truncation (i.e., can output batch with sequence lengthsgreater than the model maximum admissible input size)."
        },
        {
            "name": "max_length",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Controls the maximum length to use by one of the truncation/padding parameters.If left unset or set to None, this will use the predefined model maximum length if a maximum lengthis required by one of the truncation/padding parameters. If the model has no specific maximum inputlength (like XLNet) truncation/padding to a maximum length will be deactivated."
        },
        {
            "name": "stride",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "If set to a number along with max_length, the overflowing tokens returned whenreturn_overflowing_tokens=True will contain some tokens from the end of the truncated sequencereturned to provide some overlap between truncated and overflowing sequences. The value of thisargument defines the number of overlapping tokens."
        },
        {
            "name": "is_split_into_words",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not the input is already pre-tokenized (e.g., split into words). If set to True, thetokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)which it will tokenize. This is useful for NER or token classification."
        },
        {
            "name": "pad_to_multiple_of",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "If set will pad the sequence to a multiple of the provided value. Requires padding to be activated.This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability>= 7.5 (Volta)."
        },
        {
            "name": "padding_side",
            "type": "str",
            "optional": true,
            "default": "",
            "description": "The side on which the model should have padding applied. Should be selected between [right, left].Default value is picked from the class attribute of the same name."
        },
        {
            "name": "return_tensors",
            "type": "str,TensorType",
            "optional": true,
            "default": "",
            "description": "If set, will return tensors instead of list of python integers. Acceptable values are:tf: Return TensorFlow tf.constant objects.pt: Return PyTorch torch.Tensor objects.np: Return Numpy np.ndarray objects."
        },
        {
            "name": "return_token_type_ids",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to return token type IDs. If left to the default, will return the token type IDs according tothe specific tokenizers default, defined by the return_outputs attribute.What are token type IDs?"
        },
        {
            "name": "return_attention_mask",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to return the attention mask. If left to the default, will return the attention mask accordingto the specific tokenizers default, defined by the return_outputs attribute.What are attention masks?"
        },
        {
            "name": "return_overflowing_tokens",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to return overflowing token sequences. If a pair of sequences of input ids (or a batchof pairs) is provided with truncation_strategy = longest_first or True, an error is raised insteadof returning overflowing tokens."
        },
        {
            "name": "return_special_tokens_mask",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to return special tokens mask information."
        },
        {
            "name": "return_offsets_mapping",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to return (char_start, char_end) for each token.This is only available on fast tokenizers inheriting from PreTrainedTokenizerFast, if usingPythons tokenizer, this method will raise NotImplementedError."
        },
        {
            "name": "return_length",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to return the lengths of the encoded inputs."
        },
        {
            "name": "verbose",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to print more information and warnings."
        },
        {
            "name": "*kwargs",
            "type": "s",
            "optional": false,
            "default": "",
            "description": "passed to the self.tokenize() method"
        }
    ],
    "return": "BatchEncoding"
}