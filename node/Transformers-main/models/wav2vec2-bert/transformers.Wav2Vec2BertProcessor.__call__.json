{
    "api": "transformers.Wav2Vec2BertProcessor.__call__",
    "type": "function",
    "version": "main",
    "args_list": [
        "audio:",
        "typing.Union[ForwardRef('np.ndarray'),",
        "ForwardRef('torch.Tensor'),",
        "typing.List[ForwardRef('np.ndarray')],",
        "typing.List[ForwardRef('torch.Tensor')]]",
        "text",
        "typing.List[str],",
        "NoneType]",
        "images",
        "videos",
        "**kwargs",
        ")"
    ],
    "params": [
        {
            "name": "audio",
            "type": "np.ndarray, torch.Tensor, List[np.ndarray], List[torch.Tensor]",
            "optional": false,
            "default": "",
            "description": "The audio or batch of audios to be prepared. Each audio can be NumPy array or PyTorch tensor. In caseof a NumPy array/PyTorch tensor, each audio should be of shape (C, T), where C is a number of channels,and T the sample length of the audio."
        },
        {
            "name": "text",
            "type": "str, List[str], List[List[str]]",
            "optional": false,
            "default": "",
            "description": "The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings(pretokenized string). If the sequences are provided as list of strings (pretokenized), you must setis_split_into_words=True (to lift the ambiguity with a batch of sequences)."
        }
    ],
    "return": "BatchEncoding"
}