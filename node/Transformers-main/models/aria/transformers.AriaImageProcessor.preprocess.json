{
    "api": "transformers.AriaImageProcessor.preprocess",
    "type": "function",
    "version": "main",
    "args_list": [
        "images:",
        "typing.Union[ForwardRef('PIL.Image.Image'),",
        "numpy.ndarray,",
        "ForwardRef('torch.Tensor'),",
        "list['PIL.Image.Image'],",
        "list[numpy.ndarray],",
        "list['torch.Tensor'],",
        "typing.List[typing.Union[ForwardRef('PIL.Image.Image'),",
        "numpy.ndarray,",
        "ForwardRef('torch.Tensor'),",
        "list['PIL.Image.Image'],",
        "list[numpy.ndarray],",
        "list['torch.Tensor']]]]",
        "image_mean",
        "typing.List[float],",
        "NoneType]",
        "image_std",
        "typing.List[float],",
        "NoneType]",
        "max_image_size",
        "min_image_size",
        "split_image",
        "do_convert_rgb",
        "do_normalize",
        "resample",
        "return_tensors",
        "transformers.utils.generic.TensorType,",
        "NoneType]",
        "data_format",
        "<ChannelDimension.FIRST",
        "input_data_format",
        "transformers.image_utils.ChannelDimension,",
        "NoneType]",
        ")"
    ],
    "params": [
        {
            "name": "images",
            "type": "ImageInput,list of ImageInput",
            "optional": false,
            "default": "",
            "description": "The input image or a list of images."
        },
        {
            "name": "image_mean",
            "type": "list",
            "optional": true,
            "default": "",
            "description": "Mean values for normalization."
        },
        {
            "name": "image_std",
            "type": "list",
            "optional": true,
            "default": "",
            "description": "Standard deviation values for normalization."
        },
        {
            "name": "max_image_size",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Maximum image size."
        },
        {
            "name": "min_image_size",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Minimum image size."
        },
        {
            "name": "split_image",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to split the image."
        },
        {
            "name": "do_convert_rgb",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to convert the image to RGB."
        },
        {
            "name": "do_normalize",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to normalize the image."
        },
        {
            "name": "resample",
            "type": "PILImageResampling",
            "optional": true,
            "default": "",
            "description": "The resampling filter to use if resizing the image."
        },
        {
            "name": "return_tensors",
            "type": "str,TensorType",
            "optional": true,
            "default": "",
            "description": "The type of tensor to return."
        },
        {
            "name": "data_format",
            "type": "str,ChannelDimension",
            "optional": true,
            "default": "",
            "description": "The channel dimension format for the output image. Can be one of:channels_first or ChannelDimension.FIRST:image in (num_channels, height, width) format.channels_last or ChannelDimension.LAST:image in (height, width, num_channels) format.If unset, will use same as the input image."
        },
        {
            "name": "input_data_format",
            "type": "str,ChannelDimension",
            "optional": true,
            "default": "",
            "description": "The channel dimension format for the input image. Can be one of:channels_first or ChannelDimension.FIRST:image in (num_channels, height, width) format.channels_last or ChannelDimension.LAST:image in (height, width, num_channels) format.If unset, will use the inferred format of the input image."
        }
    ],
    "return": "BatchFeature"
}