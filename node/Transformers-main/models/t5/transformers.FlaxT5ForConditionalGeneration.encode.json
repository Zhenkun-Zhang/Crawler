{
    "api": "transformers.FlaxT5ForConditionalGeneration.encode",
    "type": "function",
    "version": "main",
    "args_list": [
        "input_ids:",
        "Array",
        "attention_mask",
        "output_attentions",
        "output_hidden_states",
        "return_dict",
        "train",
        "params",
        "dropout_rng",
        "PRNGKey",
        "at",
        "0x7f3a03b75090>",
        ")"
    ],
    "params": [
        {
            "name": "input_ids",
            "type": "jnp.ndarray of shape (batch_size, sequence_length)",
            "optional": false,
            "default": "",
            "description": "Indices of input sequence tokens in the vocabulary. T5 is a model with relative position embeddings so youshould be able to pad the inputs on both the right and the left.Indices can be obtained using AutoTokenizer. See PreTrainedTokenizer.encode() andPreTrainedTokenizer.call() for detail.To know more on how to prepare input_ids for pretraining take a look a T5 Training."
        },
        {
            "name": "attention_mask",
            "type": "jnp.ndarray of shape (batch_size, sequence_length",
            "optional": true,
            "default": "",
            "description": "Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]:1 for tokens that are not masked,0 for tokens that are masked.What are attention masks?"
        },
        {
            "name": "output_attentions",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to return the attentions tensors of all attention layers. See attentions under returnedtensors for more detail."
        },
        {
            "name": "output_hidden_states",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to return the hidden states of all layers. See hidden_states under returned tensors formore detail."
        },
        {
            "name": "return_dict",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to return a ModelOutput instead of a plain tuple."
        }
    ],
    "return": "transformers.modeling_flax_outputs.FlaxBaseModelOutput or tuple(torch.FloatTensor)"
}