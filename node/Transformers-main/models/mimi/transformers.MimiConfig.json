{
    "api": "transformers.MimiConfig",
    "type": "class",
    "version": "main",
    "args_list": [
        "sampling_rate",
        "frame_rate",
        "audio_channels",
        "hidden_size",
        "num_filters",
        "num_residual_layers",
        "upsampling_ratios",
        "kernel_size",
        "last_kernel_size",
        "residual_kernel_size",
        "dilation_growth_rate",
        "use_causal_conv",
        "pad_mode",
        "compress",
        "trim_right_ratio",
        "codebook_size",
        "codebook_dim",
        "num_quantizers",
        "use_conv_shortcut",
        "vector_quantization_hidden_dimension",
        "num_semantic_quantizers",
        "upsample_groups",
        "num_hidden_layers",
        "intermediate_size",
        "num_attention_heads",
        "num_key_value_heads",
        "head_dim",
        "hidden_act",
        "max_position_embeddings",
        "initializer_range",
        "norm_eps",
        "use_cache",
        "rope_theta",
        "sliding_window",
        "attention_dropout",
        "layer_scale_initial_scale",
        "attention_bias",
        "**kwargs"
    ],
    "params": [
        {
            "name": "sampling_rate",
            "type": "int",
            "optional": true,
            "default": "24000",
            "description": "The sampling rate at which the audio waveform should be digitalized expressed in hertz (Hz)."
        },
        {
            "name": "frame_rate",
            "type": "float",
            "optional": true,
            "default": "12.5",
            "description": "Framerate of the model."
        },
        {
            "name": "audio_channels",
            "type": "int",
            "optional": true,
            "default": "1",
            "description": "Number of channels in the audio data. Either 1 for mono or 2 for stereo."
        },
        {
            "name": "hidden_size",
            "type": "int",
            "optional": true,
            "default": "512",
            "description": "Intermediate representation dimension."
        },
        {
            "name": "num_filters",
            "type": "int",
            "optional": true,
            "default": "64",
            "description": "Number of convolution kernels of first MimiConv1d down sampling layer."
        },
        {
            "name": "num_residual_layers",
            "type": "int,  optional, defaults to 1",
            "optional": true,
            "default": "1",
            "description": "Number of residual layers."
        },
        {
            "name": "upsampling_ratios",
            "type": "Sequence[int]",
            "optional": true,
            "default": "None",
            "description": "Kernel size and stride ratios. The encoder uses downsampling ratios instead of upsampling ratios, hence itwill use the ratios in the reverse order to the ones specified here that must match the decoder order.If not specified, will defaults to [8, 6, 5, 4]"
        },
        {
            "name": "kernel_size",
            "type": "int",
            "optional": true,
            "default": "7",
            "description": "Kernel size for the initial convolution."
        },
        {
            "name": "last_kernel_size",
            "type": "int",
            "optional": true,
            "default": "3",
            "description": "Kernel size for the last convolution layer."
        },
        {
            "name": "residual_kernel_size",
            "type": "int",
            "optional": true,
            "default": "3",
            "description": "Kernel size for the residual layers."
        },
        {
            "name": "dilation_growth_rate",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "How much to increase the dilation with each layer."
        },
        {
            "name": "use_causal_conv",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether to use fully causal convolution."
        },
        {
            "name": "pad_mode",
            "type": "str",
            "optional": true,
            "default": "constant",
            "description": "Padding mode for the convolutions."
        },
        {
            "name": "compress",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "Reduced dimensionality in residual branches."
        },
        {
            "name": "trim_right_ratio",
            "type": "float",
            "optional": true,
            "default": "1.0",
            "description": "Ratio for trimming at the right of the transposed convolution under the use_causal_conv = True setup. Ifequal to 1.0, it means that all the trimming is done at the right."
        },
        {
            "name": "codebook_size",
            "type": "int",
            "optional": true,
            "default": "2048",
            "description": "Number of discret codes in each codebooks."
        },
        {
            "name": "codebook_dim",
            "type": "int",
            "optional": true,
            "default": "256",
            "description": "Dimension of the unquantized codebook vectors. If not defined, uses hidden_size."
        },
        {
            "name": "num_quantizers",
            "type": "int",
            "optional": true,
            "default": "32",
            "description": "Number of quantizer channels, or codebooks, in the quantizer."
        },
        {
            "name": "use_conv_shortcut",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether to use a convolutional layer as the skip connection in the MimiResnetBlock block. If False,an identity function will be used, giving a generic residual connection."
        },
        {
            "name": "vector_quantization_hidden_dimension",
            "type": "int",
            "optional": true,
            "default": "256",
            "description": "Intermediate representation dimension in the residual vector quantization space."
        },
        {
            "name": "num_semantic_quantizers",
            "type": "int",
            "optional": true,
            "default": "1",
            "description": "Number of semantic quantizer channels, or codebooks, in the semantic quantizer. Must be lower than num_quantizers."
        },
        {
            "name": "upsample_groups",
            "type": "int",
            "optional": true,
            "default": "512",
            "description": "If frame_rate!=encodec_frame_rate, indicates the number of groups used in the upsampling operation to go from one rate to another."
        },
        {
            "name": "num_hidden_layers",
            "type": "int",
            "optional": true,
            "default": "8",
            "description": "Number of hidden layers in the Transformer models."
        },
        {
            "name": "intermediate_size",
            "type": "int",
            "optional": true,
            "default": "2048",
            "description": "Dimension of the MLP representations."
        },
        {
            "name": "num_attention_heads",
            "type": "int",
            "optional": true,
            "default": "8",
            "description": "Number of attention heads for each attention layer in the Transformer encoder."
        },
        {
            "name": "num_key_value_heads",
            "type": "int",
            "optional": true,
            "default": "8",
            "description": "This is the number of key_value heads that should be used to implement Grouped Query Attention. Ifnum_key_value_heads=num_attention_heads, the model will use Multi Head Attention (MHA), ifnum_key_value_heads=1 the model will use Multi Query Attention (MQA) otherwise GQA is used. Whenconverting a multi-head checkpoint to a GQA checkpoint, each group key and value head should be constructedby meanpooling all the original heads within that group. For more details checkout thispaper. If it is not specified, will default to 8."
        },
        {
            "name": "head_dim",
            "type": "int",
            "optional": true,
            "default": "None",
            "description": "The attention head dimension."
        },
        {
            "name": "hidden_act",
            "type": "str,function",
            "optional": true,
            "default": "gelu",
            "description": "The non-linear activation function (function or string) in the decoder."
        },
        {
            "name": "max_position_embeddings",
            "type": "int",
            "optional": true,
            "default": "8000",
            "description": "The maximum sequence length that this model might ever be used with. Mimis sliding window attentionallows sequence of up to 8000 tokens."
        },
        {
            "name": "initializer_range",
            "type": "float",
            "optional": true,
            "default": "0.02",
            "description": "The standard deviation of the truncated_normal_initializer for initializing all weight matrices."
        },
        {
            "name": "norm_eps",
            "type": "float",
            "optional": true,
            "default": "1e-05",
            "description": "The epsilon used by the LayerNorm normalization layers."
        },
        {
            "name": "use_cache",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether or not the model should return the last key/values attentions (not used by all models). Onlyrelevant if config.is_decoder=True."
        },
        {
            "name": "rope_theta",
            "type": "float",
            "optional": true,
            "default": "10000.0",
            "description": "The base period of the RoPE embeddings."
        },
        {
            "name": "sliding_window",
            "type": "int",
            "optional": true,
            "default": "250",
            "description": "Sliding window attention window size. If not specified, will default to 250."
        },
        {
            "name": "attention_dropout",
            "type": "float",
            "optional": true,
            "default": "0.0",
            "description": "The dropout ratio for the attention probabilities."
        },
        {
            "name": "layer_scale_initial_scale",
            "type": "float",
            "optional": true,
            "default": "0.01",
            "description": "Initiale scale of the residual rescaling operation done in the Transformer models."
        },
        {
            "name": "attention_bias",
            "type": "bool, defaults to False",
            "optional": true,
            "default": "False",
            "description": "Whether to use a bias in the query, key, value and output projection layers during self-attention."
        }
    ],
    "return": ""
}