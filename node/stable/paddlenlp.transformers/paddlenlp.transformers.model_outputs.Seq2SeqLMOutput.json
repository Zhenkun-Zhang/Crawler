{
    "api": "paddlenlp.transformers.model_outputs.Seq2SeqLMOutput",
    "type": "class",
    "version": "stable",
    "args_list": {
        "loss": "Tensor or None = None",
        "logits": "Tensor or None = None",
        "past_key_values": "Tuple[Tuple[Tensor]] or None = None",
        "decoder_hidden_states": "Tuple[Tensor] or None = None",
        "decoder_attentions": "Tuple[Tensor] or None = None",
        "cross_attentions": "Tuple[Tensor] or None = None",
        "encoder_last_hidden_state": "Tensor or None = None",
        "encoder_hidden_states": "Tuple[Tensor] or None = None",
        "encoder_attentions": "Tuple[Tensor] or None = None"
    },
    "Bases": "",
    "description": "Base class for sequence-to-sequence language models outputs.",
    "params": [
        {
            "name": "loss",
            "type": "paddle.Tensor",
            "description": "Language modeling loss whose shape is (1,). Returned when labels is provided.",
            "default": "",
            "optional": true
        },
        {
            "name": "logits",
            "type": "paddle.Tensor",
            "description": "Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax) whose shape is (batch_size, sequence_length, config.vocab_size)).",
            "default": "",
            "optional": false
        },
        {
            "name": "past_key_values",
            "type": "tupletuplepaddle.Tensor",
            "description": "Tuple of tuple(paddle.Tensor) of length config.n_layers, with each tuple having 2 tensors of shape(batch_size, num_heads, sequence_length, embed_size_per_head)) and 2 additional tensors of shape(batch_size, num_heads, encoder_sequence_length, embed_size_per_head).Returned when use_cache=True is passed or when config.use_cache=True.Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attentionblocks) that can be used (see past_key_values input) to speed up sequential decoding.Tuple of tuple(paddle.Tensor) of length config.n_layers, with each tuple having 2 tensors of shape(batch_size, num_heads, sequence_length, embed_size_per_head)) and 2 additional tensors of shape(batch_size, num_heads, encoder_sequence_length, embed_size_per_head).Returned when use_cache=True is passed or when config.use_cache=True.",
            "default": "",
            "optional": true
        },
        {
            "name": "decoder_hidden_states",
            "type": "tuplepaddle.Tensor",
            "description": "Tuple of paddle.Tensor (one for the output of the embeddings, if the model has an embedding layer, +one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).Returned when output_hidden_states=True is passed or when config.output_hidden_states=True.Hidden-states of the decoder at the output of each layer plus the initial embedding outputs.Tuple of paddle.Tensor (one for the output of the embeddings, if the model has an embedding layer, +one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).Returned when output_hidden_states=True is passed or when config.output_hidden_states=True.",
            "default": "",
            "optional": true
        },
        {
            "name": "decoder_attentions",
            "type": "tuplepaddle.Tensor",
            "description": "Tuple of paddle.Tensor (one for each layer) of shape (batch_size, num_heads, sequence_length,sequence_length).Returned when output_attentions=True is passed or when config.output_attentions=True.Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in theself-attention heads.Tuple of paddle.Tensor (one for each layer) of shape (batch_size, num_heads, sequence_length,sequence_length).Returned when output_attentions=True is passed or when config.output_attentions=True.",
            "default": "",
            "optional": true
        },
        {
            "name": "cross_attentions",
            "type": "tuplepaddle.Tensor",
            "description": "Tuple of paddle.Tensor (one for each layer) of shape (batch_size, num_heads, sequence_length,sequence_length).Returned when output_attentions=True is passed or when config.output_attentions=True.Attentions weights of the decoders cross-attention layer, after the attention softmax, used to compute theweighted average in the cross-attention heads.Tuple of paddle.Tensor (one for each layer) of shape (batch_size, num_heads, sequence_length,sequence_length).Returned when output_attentions=True is passed or when config.output_attentions=True.",
            "default": "",
            "optional": true
        },
        {
            "name": "encoder_last_hidden_state",
            "type": "paddle.Tensor",
            "description": "Sequence of hidden-states at the output of the last layer of the encoder of the model whose shape is (batch_size, sequence_length, hidden_size).",
            "default": "",
            "optional": true
        },
        {
            "name": "encoder_hidden_states",
            "type": "tuplepaddle.Tensor",
            "description": "Tuple of paddle.Tensor (one for the output of the embeddings, if the model has an embedding layer, +one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).Hidden-states of the encoder at the output of each layer plus the initial embedding outputs.Tuple of paddle.Tensor (one for the output of the embeddings, if the model has an embedding layer, +one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).",
            "default": "",
            "optional": true
        },
        {
            "name": "encoder_attentions",
            "type": "tuplepaddle.Tensor",
            "description": "Tuple of paddle.Tensor (one for each layer) of shape (batch_size, num_heads, sequence_length,sequence_length).Returned when output_attentions=True is passed or when config.output_attentions=True.Attentions weights of the encoder, after the attention softmax, used to compute the weighted average in theself-attention heads.Tuple of paddle.Tensor (one for each layer) of shape (batch_size, num_heads, sequence_length,sequence_length).Returned when output_attentions=True is passed or when config.output_attentions=True.",
            "default": "",
            "optional": true
        }
    ],
    "return": {
        "description": "",
        "type": ""
    }
}