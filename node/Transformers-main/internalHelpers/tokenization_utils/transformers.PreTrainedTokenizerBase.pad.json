{
    "api": "transformers.PreTrainedTokenizerBase.pad",
    "type": "function",
    "version": "main",
    "args_list": [
        "encoded_inputs:",
        "typing.Union[transformers.tokenization_utils_base.BatchEncoding,",
        "typing.List[transformers.tokenization_utils_base.BatchEncoding],",
        "typing.Dict[str,",
        "typing.List[int]],",
        "typing.Dict[str,",
        "typing.List[typing.List[int]]],",
        "typing.List[typing.Dict[str,",
        "typing.List[int]]]]",
        "padding",
        "str,",
        "transformers.utils.generic.PaddingStrategy]",
        "max_length",
        "pad_to_multiple_of",
        "padding_side",
        "return_attention_mask",
        "return_tensors",
        "transformers.utils.generic.TensorType,",
        "NoneType]",
        "verbose"
    ],
    "params": [
        {
            "name": "encoded_inputs",
            "type": "BatchEncoding, list of BatchEncoding, Dict[str, List[int]], Dict[str, List[List[int]],List[Dict[str, List[int]]]",
            "optional": false,
            "default": "",
            "description": "Tokenized inputs. Can represent one input (BatchEncoding or Dict[str, List[int]]) or a batch oftokenized inputs (list of BatchEncoding, Dict[str, List[List[int]]] or List[Dict[str,List[int]]]) so you can use this method during preprocessing as well as in a PyTorch Dataloadercollate function.Instead of List[int] you can have tensors (numpy arrays, PyTorch tensors or TensorFlow tensors), seethe note above for the return type."
        },
        {
            "name": "padding",
            "type": "bool, str,PaddingStrategy",
            "optional": true,
            "default": "",
            "description": "Select a strategy to pad the returned sequences (according to the models padding side and paddingindex) among:True or longest (default): Pad to the longest sequence in the batch (or no padding if only a singlesequence if provided).max_length: Pad to a maximum length specified with the argument max_length or to the maximumacceptable input length for the model if that argument is not provided.False or do_not_pad: No padding (i.e., can output a batch with sequences of differentlengths)."
        },
        {
            "name": "max_length",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Maximum length of the returned list and optionally padding length (see above)."
        },
        {
            "name": "pad_to_multiple_of",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "If set will pad the sequence to a multiple of the provided value.This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability>= 7.5 (Volta)."
        },
        {
            "name": "padding_side",
            "type": "str",
            "optional": true,
            "default": "",
            "description": "The side on which the model should have padding applied. Should be selected between [right, left].Default value is picked from the class attribute of the same name."
        },
        {
            "name": "return_attention_mask",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to return the attention mask. If left to the default, will return the attention mask accordingto the specific tokenizers default, defined by the return_outputs attribute.What are attention masks?"
        },
        {
            "name": "return_tensors",
            "type": "str,TensorType",
            "optional": true,
            "default": "",
            "description": "If set, will return tensors instead of list of python integers. Acceptable values are:tf: Return TensorFlow tf.constant objects.pt: Return PyTorch torch.Tensor objects.np: Return Numpy np.ndarray objects."
        },
        {
            "name": "verbose",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether or not to print more information and warnings."
        }
    ],
    "return": ""
}