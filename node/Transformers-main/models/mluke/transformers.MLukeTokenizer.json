{
    "api": "transformers.MLukeTokenizer",
    "type": "class",
    "version": "main",
    "args_list": [
        "vocab_file",
        "entity_vocab_file",
        "bos_token",
        "eos_token",
        "sep_token",
        "cls_token",
        "unk_token",
        "pad_token",
        "mask_token",
        "task",
        "max_entity_length",
        "max_mention_length",
        "entity_token_1",
        "entity_token_2",
        "entity_unk_token",
        "entity_pad_token",
        "entity_mask_token",
        "entity_mask2_token",
        "sp_model_kwargs",
        "typing.Any]]",
        "**kwargs"
    ],
    "params": [
        {
            "name": "vocab_file",
            "type": "str",
            "optional": false,
            "default": "",
            "description": "Path to the vocabulary file."
        },
        {
            "name": "entity_vocab_file",
            "type": "str",
            "optional": false,
            "default": "",
            "description": "Path to the entity vocabulary file."
        },
        {
            "name": "bos_token",
            "type": "str",
            "optional": true,
            "default": "<s>",
            "description": "The beginning of sequence token that was used during pretraining. Can be used a sequence classifier token.When building a sequence using special tokens, this is not the token that is used for the beginning ofsequence. The token used is the cls_token."
        },
        {
            "name": "eos_token",
            "type": "str",
            "optional": true,
            "default": "</s>",
            "description": "The end of sequence token.When building a sequence using special tokens, this is not the token that is used for the end of sequence.The token used is the sep_token."
        },
        {
            "name": "sep_token",
            "type": "str",
            "optional": true,
            "default": "</s>",
            "description": "The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences forsequence classification or for a text and a question for question answering. It is also used as the lasttoken of a sequence built with special tokens."
        },
        {
            "name": "cls_token",
            "type": "str",
            "optional": true,
            "default": "<s>",
            "description": "The classifier token which is used when doing sequence classification (classification of the whole sequenceinstead of per-token classification). It is the first token of the sequence when built with special tokens."
        },
        {
            "name": "unk_token",
            "type": "str",
            "optional": true,
            "default": "<unk>",
            "description": "The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be thistoken instead."
        },
        {
            "name": "pad_token",
            "type": "str",
            "optional": true,
            "default": "<pad>",
            "description": "The token used for padding, for example when batching sequences of different lengths."
        },
        {
            "name": "mask_token",
            "type": "str",
            "optional": true,
            "default": "<mask>",
            "description": "The token used for masking values. This is the token used when training this model with masked languagemodeling. This is the token which the model will try to predict."
        },
        {
            "name": "task",
            "type": "str",
            "optional": true,
            "default": "None",
            "description": "Task for which you want to prepare sequences. One of entity_classification,entity_pair_classification, or entity_span_classification. If you specify this argument, the entitysequence is automatically created based on the given entity span(s)."
        },
        {
            "name": "max_entity_length",
            "type": "int",
            "optional": true,
            "default": "32",
            "description": "The maximum length of entity_ids."
        },
        {
            "name": "max_mention_length",
            "type": "int",
            "optional": true,
            "default": "30",
            "description": "The maximum number of tokens inside an entity span."
        },
        {
            "name": "entity_token_1",
            "type": "str",
            "optional": true,
            "default": "<ent>",
            "description": "The special token used to represent an entity span in a word token sequence. This token is only used whentask is set to entity_classification or entity_pair_classification."
        },
        {
            "name": "entity_token_2",
            "type": "str",
            "optional": true,
            "default": "<ent2>",
            "description": "The special token used to represent an entity span in a word token sequence. This token is only used whentask is set to entity_pair_classification."
        },
        {
            "name": "additional_special_tokens",
            "type": "List[str]",
            "optional": true,
            "default": "",
            "description": "Additional special tokens used by the tokenizer."
        },
        {
            "name": "sp_model_kwargs",
            "type": "dict",
            "optional": true,
            "default": "",
            "description": "Will be passed to the SentencePieceProcessor.__init__() method. The Python wrapper forSentencePiece can be used, among other things,to set:enable_sampling: Enable subword regularization.nbest_size: Sampling parameters for unigram. Invalid for BPE-Dropout.nbest_size = {0,1}: No sampling is performed.nbest_size > 1: samples from the nbest_size results.nbest_size < 0: assuming that nbest_size is infinite and samples from the all hypothesis (lattice)using forward-filtering-and-backward-sampling algorithm.alpha: Smoothing parameter for unigram sampling, and dropout probability of merge operations forBPE-dropout."
        },
        {
            "name": "sp_model",
            "type": "SentencePieceProcessor",
            "optional": false,
            "default": "",
            "description": "The SentencePiece processor that is used for every conversion (string, tokens and IDs)."
        }
    ],
    "return": ""
}