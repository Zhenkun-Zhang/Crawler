{
    "api": "transformers.CompressedTensorsConfig",
    "type": "class",
    "version": "main",
    "args_list": [
        "config_groups:",
        "typing.Union[ForwardRef('QuantizationScheme'),",
        "typing.List[str]]]",
        "format",
        "quantization_status",
        "kv_cache_scheme",
        "global_compression_ratio",
        "ignore",
        "sparsity_config",
        "typing.Any]",
        "quant_method",
        "run_compressed",
        "**kwargs"
    ],
    "params": [
        {
            "name": "config_groups",
            "type": "typing.Dict[str, typing.Union[ForwardRef('QuantizationScheme'), typing.List[str]]]",
            "optional": true,
            "default": "",
            "description": "dictionary mapping group name to a quantization scheme definition"
        },
        {
            "name": "format",
            "type": "str",
            "optional": true,
            "default": "",
            "description": "format the model is represented as. Set run_compressed True to execute model as thecompressed format if not dense"
        },
        {
            "name": "quantization_status",
            "type": "QuantizationStatus",
            "optional": true,
            "default": "",
            "description": "status of model in the quantization lifecycle, ie initialized, calibration, frozen"
        },
        {
            "name": "kv_cache_scheme",
            "type": "typing.Union[QuantizationArgs, NoneType]",
            "optional": true,
            "default": "",
            "description": "specifies quantization of the kv cache. If None, kv cache is not quantized."
        },
        {
            "name": "global_compression_ratio",
            "type": "typing.Union[float, NoneType]",
            "optional": true,
            "default": "",
            "description": "0-1 float percentage of model compression"
        },
        {
            "name": "ignore",
            "type": "typing.Union[typing.List[str], NoneType]",
            "optional": true,
            "default": "",
            "description": "layer names or types to not quantize, supports regex prefixed by re:"
        },
        {
            "name": "sparsity_config",
            "type": "typing.Dict[str, typing.Any]",
            "optional": true,
            "default": "",
            "description": "configuration for sparsity compression"
        },
        {
            "name": "quant_method",
            "type": "str",
            "optional": true,
            "default": "",
            "description": "do not override, should be compressed-tensors"
        },
        {
            "name": "run_compressed",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "alter submodules (usually linear) in order toemulate compressed model execution if True, otherwise use default submodule"
        }
    ],
    "return": ""
}