{
    "api": "transformers.ZoeDepthImageProcessor.preprocess",
    "type": "function",
    "version": "main",
    "args_list": [
        "images:",
        "typing.Union[ForwardRef('PIL.Image.Image'),",
        "numpy.ndarray,",
        "ForwardRef('torch.Tensor'),",
        "list['PIL.Image.Image'],",
        "list[numpy.ndarray],",
        "list['torch.Tensor']]",
        "do_pad",
        "do_rescale",
        "rescale_factor",
        "do_normalize",
        "image_mean",
        "typing.List[float],",
        "NoneType]",
        "image_std",
        "typing.List[float],",
        "NoneType]",
        "do_resize",
        "size",
        "keep_aspect_ratio",
        "ensure_multiple_of",
        "resample",
        "return_tensors",
        "transformers.utils.generic.TensorType,",
        "NoneType]",
        "data_format",
        "<ChannelDimension.FIRST",
        "input_data_format",
        "transformers.image_utils.ChannelDimension,",
        "NoneType]"
    ],
    "params": [
        {
            "name": "images",
            "type": "ImageInput",
            "optional": false,
            "default": "",
            "description": "Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. Ifpassing in images with pixel values between 0 and 1, set do_rescale=False."
        },
        {
            "name": "do_pad",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to pad the input image."
        },
        {
            "name": "do_rescale",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to rescale the image values between [0 - 1]."
        },
        {
            "name": "rescale_factor",
            "type": "float",
            "optional": true,
            "default": "",
            "description": "Rescale factor to rescale the image by if do_rescale is set to True."
        },
        {
            "name": "do_normalize",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to normalize the image."
        },
        {
            "name": "image_mean",
            "type": "float,List[float]",
            "optional": true,
            "default": "",
            "description": "Image mean."
        },
        {
            "name": "image_std",
            "type": "float,List[float]",
            "optional": true,
            "default": "",
            "description": "Image standard deviation."
        },
        {
            "name": "do_resize",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to resize the image."
        },
        {
            "name": "size",
            "type": "Dict[str, int]",
            "optional": true,
            "default": "",
            "description": "Size of the image after resizing. If keep_aspect_ratio is True, he image is resized by choosing thesmaller of the height and width scaling factors and using it for both dimensions. If ensure_multiple_ofis also set, the image is further resized to a size that is a multiple of this value."
        },
        {
            "name": "keep_aspect_ratio",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "If True and do_resize=True, the image is resized by choosing the smaller of the height and widthscaling factors and using it for both dimensions. This ensures that the image is scaled down as littleas possible while still fitting within the desired output size. In case ensure_multiple_of is alsoset, the image is further resized to a size that is a multiple of this value by flooring the height andwidth to the nearest multiple of this value."
        },
        {
            "name": "ensure_multiple_of",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "If do_resize is True, the image is resized to a size that is a multiple of this value. Works byflooring the height and width to the nearest multiple of this value.Works both with and without keep_aspect_ratio being set to True. Can be overidden byensure_multiple_of in preprocess."
        },
        {
            "name": "resample",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Resampling filter to use if resizing the image. This can be one of the enum PILImageResampling, Onlyhas an effect if do_resize is set to True."
        },
        {
            "name": "return_tensors",
            "type": "str,TensorType",
            "optional": true,
            "default": "",
            "description": "The type of tensors to return. Can be one of:Unset: Return a list of np.ndarray.TensorType.TENSORFLOW or tf: Return a batch of type tf.Tensor.TensorType.PYTORCH or pt: Return a batch of type torch.Tensor.TensorType.NUMPY or np: Return a batch of type np.ndarray.TensorType.JAX or jax: Return a batch of type jax.numpy.ndarray."
        },
        {
            "name": "data_format",
            "type": "ChannelDimension,str",
            "optional": true,
            "default": "",
            "description": "The channel dimension format for the output image. Can be one of:ChannelDimension.FIRST: image in (num_channels, height, width) format.ChannelDimension.LAST: image in (height, width, num_channels) format."
        },
        {
            "name": "input_data_format",
            "type": "ChannelDimension,str",
            "optional": true,
            "default": "",
            "description": "The channel dimension format for the input image. If unset, the channel dimension format is inferredfrom the input image. Can be one of:channels_first or ChannelDimension.FIRST: image in (num_channels, height, width) format.channels_last or ChannelDimension.LAST: image in (height, width, num_channels) format.none or ChannelDimension.NONE: image in (height, width) format."
        }
    ],
    "return": ""
}