{
    "api": "transformers.ClapAudioConfig",
    "type": "class",
    "version": "main",
    "args_list": [
        "window_size",
        "num_mel_bins",
        "spec_size",
        "hidden_act",
        "patch_size",
        "patch_stride",
        "4]",
        "num_classes",
        "hidden_size",
        "projection_dim",
        "depths",
        "2,",
        "6,",
        "2]",
        "num_attention_heads",
        "8,",
        "16,",
        "32]",
        "enable_fusion",
        "hidden_dropout_prob",
        "fusion_type",
        "patch_embed_input_channels",
        "flatten_patch_embeds",
        "patch_embeds_hidden_size",
        "enable_patch_layer_norm",
        "drop_path_rate",
        "attention_probs_dropout_prob",
        "qkv_bias",
        "mlp_ratio",
        "aff_block_r",
        "num_hidden_layers",
        "projection_hidden_act",
        "layer_norm_eps",
        "initializer_factor",
        "**kwargs"
    ],
    "params": [
        {
            "name": "window_size",
            "type": "int",
            "optional": true,
            "default": "8",
            "description": "Image size of the spectrogram"
        },
        {
            "name": "num_mel_bins",
            "type": "int",
            "optional": true,
            "default": "64",
            "description": "Number of mel features used per frames. Should correspond to the value used in the ClapProcessor class."
        },
        {
            "name": "spec_size",
            "type": "int",
            "optional": true,
            "default": "256",
            "description": "Desired input size of the spectrogram that the model supports. It can be different from the output of theClapFeatureExtractor, in which case the input features will be resized. Corresponds to the image_sizeof the audio models."
        },
        {
            "name": "hidden_act",
            "type": "str",
            "optional": true,
            "default": "gelu",
            "description": "The non-linear activation function (function or string) in the encoder and pooler. If string, gelu,relu, silu and gelu_new are supported."
        },
        {
            "name": "patch_size",
            "type": "int",
            "optional": true,
            "default": "4",
            "description": "Patch size for the audio spectrogram"
        },
        {
            "name": "patch_stride",
            "type": "list",
            "optional": true,
            "default": "[4,",
            "description": "Patch stride for the audio spectrogram"
        },
        {
            "name": "num_classes",
            "type": "int",
            "optional": true,
            "default": "527",
            "description": "Number of classes used for the head training"
        },
        {
            "name": "hidden_size",
            "type": "int",
            "optional": true,
            "default": "768",
            "description": "Hidden size of the output of the audio encoder. Correspond to the dimension of the penultimate layersoutput,which is sent to the projection MLP layer."
        },
        {
            "name": "projection_dim",
            "type": "int",
            "optional": true,
            "default": "512",
            "description": "Hidden size of the projection layer."
        },
        {
            "name": "depths",
            "type": "list",
            "optional": true,
            "default": "[2,",
            "description": "Depths used for the Swin Layers of the audio model"
        },
        {
            "name": "num_attention_heads",
            "type": "list",
            "optional": true,
            "default": "[4,",
            "description": "Number of attention heads used for the Swin Layers of the audio model"
        },
        {
            "name": "enable_fusion",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether or not to enable patch fusion. This is the main contribution of the authors, and should give thebest results."
        },
        {
            "name": "hidden_dropout_prob",
            "type": "float",
            "optional": true,
            "default": "0.1",
            "description": "The dropout probability for all fully connected layers in the encoder."
        },
        {
            "name": "fusion_type",
            "type": "[type]",
            "optional": true,
            "default": "None",
            "description": "Fusion type used for the patch fusion."
        },
        {
            "name": "patch_embed_input_channels",
            "type": "int",
            "optional": true,
            "default": "1",
            "description": "Number of channels used for the input spectrogram"
        },
        {
            "name": "flatten_patch_embeds",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not to flatten the patch embeddings"
        },
        {
            "name": "patch_embeds_hidden_size",
            "type": "int",
            "optional": true,
            "default": "96",
            "description": "Hidden size of the patch embeddings. It is used as the number of output channels."
        },
        {
            "name": "enable_patch_layer_norm",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not to enable layer normalization for the patch embeddings"
        },
        {
            "name": "drop_path_rate",
            "type": "float",
            "optional": true,
            "default": "0.0",
            "description": "Drop path rate for the patch fusion"
        },
        {
            "name": "attention_probs_dropout_prob",
            "type": "float",
            "optional": true,
            "default": "0.0",
            "description": "The dropout ratio for the attention probabilities."
        },
        {
            "name": "qkv_bias",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not to add a bias to the query, key, value projections."
        },
        {
            "name": "mlp_ratio",
            "type": "float",
            "optional": true,
            "default": "4.0",
            "description": "Ratio of the mlp hidden dim to embedding dim."
        },
        {
            "name": "aff_block_r",
            "type": "int",
            "optional": true,
            "default": "4",
            "description": "downsize_ratio used in the AudioFF block"
        },
        {
            "name": "num_hidden_layers",
            "type": "int",
            "optional": true,
            "default": "4",
            "description": "Number of hidden layers in the Transformer encoder."
        },
        {
            "name": "projection_hidden_act",
            "type": "str",
            "optional": true,
            "default": "relu",
            "description": "The non-linear activation function (function or string) in the projection layer. If string, gelu,relu, silu and gelu_new are supported."
        },
        {
            "name": "layer_norm_eps",
            "type": "[type]",
            "optional": true,
            "default": "1e-05",
            "description": "The epsilon used by the layer normalization layers."
        },
        {
            "name": "initializer_factor",
            "type": "float",
            "optional": true,
            "default": "1.0",
            "description": "A factor for initializing all weight matrices (should be kept to 1, used internally for initializationtesting)."
        }
    ],
    "return": ""
}