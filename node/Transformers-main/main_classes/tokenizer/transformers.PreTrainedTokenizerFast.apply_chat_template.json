{
    "api": "transformers.PreTrainedTokenizerFast.apply_chat_template",
    "type": "function",
    "version": "main",
    "args_list": [
        "conversation:",
        "typing.Union[typing.List[typing.Dict[str,",
        "str]],",
        "typing.List[typing.List[typing.Dict[str,",
        "str]]]]",
        "tools",
        "typing.Callable]]]",
        "documents",
        "str]]]",
        "chat_template",
        "add_generation_prompt",
        "continue_final_message",
        "tokenize",
        "padding",
        "str,",
        "transformers.utils.generic.PaddingStrategy]",
        "truncation",
        "max_length",
        "return_tensors",
        "transformers.utils.generic.TensorType,",
        "NoneType]",
        "return_dict",
        "return_assistant_tokens_mask",
        "tokenizer_kwargs",
        "typing.Any]]",
        "**kwargs",
        ")"
    ],
    "params": [
        {
            "name": "conversation",
            "type": "Union[List[Dict[str, str]], List[List[Dict[str, str]]]]",
            "optional": false,
            "default": "",
            "description": "A list of dictswith role and content keys, representing the chat history so far."
        },
        {
            "name": "tools",
            "type": "List[Dict]",
            "optional": true,
            "default": "",
            "description": "A list of tools (callable functions) that will be accessible to the model. If the template does notsupport function calling, this argument will have no effect. Each tool should be passed as a JSON Schema,giving the name, description and argument types for the tool. See ourchat templating guidefor more information."
        },
        {
            "name": "documents",
            "type": "List[Dict[str, str]]",
            "optional": true,
            "default": "",
            "description": "A list of dicts representing documents that will be accessible to the model if it is performing RAG(retrieval-augmented generation). If the template does not support RAG, this argument will have noeffect. We recommend that each document should be a dict containing title and text keys. Pleasesee the RAG section of the chat templating guidefor examples of passing documents with chat templates."
        },
        {
            "name": "chat_template",
            "type": "str",
            "optional": true,
            "default": "",
            "description": "A Jinja template to use for this conversion. It is usually not necessary to pass anything to thisargument, as the models template will be used by default."
        },
        {
            "name": "add_generation_prompt",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "If this is set, a prompt with the token(s) that indicatethe start of an assistant message will be appended to the formatted output. This is useful when you want to generate a response from the model.Note that this argument will be passed to the chat template, and so it must be supported in thetemplate for this argument to have any effect."
        },
        {
            "name": "continue_final_message",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "If this is set, the chat will be formatted so that the finalmessage in the chat is open-ended, without any EOS tokens. The model will continue this messagerather than starting a new one. This allows you to prefill part ofthe models response for it. Cannot be used at the same time as add_generation_prompt."
        },
        {
            "name": "tokenize",
            "type": "bool, defaults to True",
            "optional": false,
            "default": "",
            "description": "Whether to tokenize the output. If False, the output will be a string."
        },
        {
            "name": "padding",
            "type": "bool, str,PaddingStrategy",
            "optional": true,
            "default": "",
            "description": "Select a strategy to pad the returned sequences (according to the models padding side and paddingindex) among:True or longest: Pad to the longest sequence in the batch (or no padding if only a singlesequence if provided).max_length: Pad to a maximum length specified with the argument max_length or to the maximumacceptable input length for the model if that argument is not provided.False or do_not_pad (default): No padding (i.e., can output a batch with sequences of differentlengths)."
        },
        {
            "name": "truncation",
            "type": "bool, defaults to False",
            "optional": false,
            "default": "",
            "description": "Whether to truncate sequences at the maximum length. Has no effect if tokenize is False."
        },
        {
            "name": "max_length",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Maximum length (in tokens) to use for padding or truncation. Has no effect if tokenize is False. Ifnot specified, the tokenizers max_length attribute will be used as a default."
        },
        {
            "name": "return_tensors",
            "type": "str,TensorType",
            "optional": true,
            "default": "",
            "description": "If set, will return tensors of a particular framework. Has no effect if tokenize is False. Acceptablevalues are:tf: Return TensorFlow tf.Tensor objects.pt: Return PyTorch torch.Tensor objects.np: Return NumPy np.ndarray objects.jax: Return JAX jnp.ndarray objects."
        },
        {
            "name": "return_dict",
            "type": "bool, defaults to False",
            "optional": false,
            "default": "",
            "description": "Whether to return a dictionary with named outputs. Has no effect if tokenize is False."
        },
        {
            "name": "tokenizer_kwargs",
            "type": "Dict[str -- Any]",
            "optional": true,
            "default": "",
            "description": ""
        },
        {
            "name": "return_assistant_tokens_mask",
            "type": "bool, defaults to False",
            "optional": false,
            "default": "",
            "description": "Whether to return a mask of the assistant generated tokens. For tokens generated by the assistant,the mask will contain 1. For user and system tokens, the mask will contain 0.This functionality is only available for chat templates that support it via the {% generation %} keyword."
        },
        {
            "name": "*kwargs",
            "type": "s",
            "optional": false,
            "default": "",
            "description": "Additional kwargs to pass to the template renderer. Will be accessible by the chat template."
        }
    ],
    "return": "Union[List[int], Dict]"
}