{
    "api": "transformers.MambaConfig",
    "type": "class",
    "version": "main",
    "args_list": [
        "vocab_size",
        "hidden_size",
        "state_size",
        "num_hidden_layers",
        "layer_norm_epsilon",
        "pad_token_id",
        "bos_token_id",
        "eos_token_id",
        "expand",
        "conv_kernel",
        "use_bias",
        "use_conv_bias",
        "hidden_act",
        "initializer_range",
        "residual_in_fp32",
        "time_step_rank",
        "time_step_scale",
        "time_step_min",
        "time_step_max",
        "time_step_init_scheme",
        "time_step_floor",
        "rescale_prenorm_residual",
        "use_cache",
        "use_mambapy",
        "**kwargs"
    ],
    "params": [
        {
            "name": "vocab_size",
            "type": "int",
            "optional": true,
            "default": "50280",
            "description": "Vocabulary size of the MAMBA model. Defines the number of different tokens that can be represented by theinputs_ids passed when calling MambaModel."
        },
        {
            "name": "hidden_size",
            "type": "int",
            "optional": true,
            "default": "768",
            "description": "Dimensionality of the embeddings and hidden states."
        },
        {
            "name": "state_size",
            "type": "int",
            "optional": true,
            "default": "16",
            "description": "shape of the state space latents."
        },
        {
            "name": "num_hidden_layers",
            "type": "int",
            "optional": true,
            "default": "32",
            "description": "Number of hidden layers in the model."
        },
        {
            "name": "layer_norm_epsilon",
            "type": "float",
            "optional": true,
            "default": "1e-05",
            "description": "The epsilon to use in the layer normalization layers."
        },
        {
            "name": "pad_token_id",
            "type": "int",
            "optional": true,
            "default": "0",
            "description": "Padding token id."
        },
        {
            "name": "bos_token_id",
            "type": "int",
            "optional": true,
            "default": "0",
            "description": "The id of the beginning of sentence token in the vocabulary."
        },
        {
            "name": "eos_token_id",
            "type": "int",
            "optional": true,
            "default": "0",
            "description": "The id of the end of sentence token in the vocabulary."
        },
        {
            "name": "expand",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "Expanding factor used to determine the intermediate size."
        },
        {
            "name": "conv_kernel",
            "type": "int",
            "optional": true,
            "default": "4",
            "description": "Size of the convolution kernel."
        },
        {
            "name": "use_bias",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether or not to use bias in [in_proj, out_proj] of the mixer block"
        },
        {
            "name": "use_conv_bias",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not to use bias in the convolution layer of the mixer block."
        },
        {
            "name": "hidden_act",
            "type": "str",
            "optional": true,
            "default": "silu",
            "description": "The non-linear activation function (function or string) in the decoder."
        },
        {
            "name": "initializer_range",
            "type": "float",
            "optional": true,
            "default": "0.1",
            "description": "The standard deviation of the truncated_normal_initializer for initializing all weight matrices."
        },
        {
            "name": "residual_in_fp32",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not residuals should be in float32. If set to False residuals will keep the same dtype as the rest of the model"
        },
        {
            "name": "time_step_rank",
            "type": "Union[int,str]",
            "optional": true,
            "default": "auto",
            "description": "Rank of the discretization projection matrix. auto means that it will default to math.ceil(self.hidden_size / 16)"
        },
        {
            "name": "time_step_scale",
            "type": "float",
            "optional": true,
            "default": "1.0",
            "description": "Scale used used to scale dt_proj.bias."
        },
        {
            "name": "time_step_min",
            "type": "float",
            "optional": true,
            "default": "0.001",
            "description": "Minimum time_step used to bound dt_proj.bias."
        },
        {
            "name": "time_step_max",
            "type": "float",
            "optional": true,
            "default": "0.1",
            "description": "Maximum time_step used to bound dt_proj.bias."
        },
        {
            "name": "time_step_init_scheme",
            "type": "float",
            "optional": true,
            "default": "random",
            "description": "Init scheme used for dt_proj.weight. Should be one of [random,uniform]"
        },
        {
            "name": "time_step_floor",
            "type": "float",
            "optional": true,
            "default": "0.0001",
            "description": "Minimum clamping value of the dt_proj.bias layer initialization."
        },
        {
            "name": "rescale_prenorm_residual",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether or not to rescale out_proj weights when initializing."
        },
        {
            "name": "use_cache",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not the cache should be used."
        },
        {
            "name": "use_mambapy",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Determines the fallback strategy during training if the CUDA-based official implementation of Mamba is not avaiable. If True, the mamba.py implementation is used. If False, the naive and slower implementation is used. Consider switching to the naive version if memory is limited."
        }
    ],
    "return": ""
}