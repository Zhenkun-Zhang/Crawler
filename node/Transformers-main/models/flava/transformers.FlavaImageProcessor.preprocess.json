{
    "api": "transformers.FlavaImageProcessor.preprocess",
    "type": "function",
    "version": "main",
    "args_list": [
        "images:",
        "typing.Union[ForwardRef('PIL.Image.Image'),",
        "numpy.ndarray,",
        "ForwardRef('torch.Tensor'),",
        "list['PIL.Image.Image'],",
        "list[numpy.ndarray],",
        "list['torch.Tensor']]",
        "do_resize",
        "size",
        "int]",
        "resample",
        "do_center_crop",
        "crop_size",
        "int]]",
        "do_rescale",
        "rescale_factor",
        "do_normalize",
        "image_mean",
        "typing.List[float],",
        "NoneType]",
        "image_std",
        "typing.List[float],",
        "NoneType]",
        "return_image_mask",
        "input_size_patches",
        "total_mask_patches",
        "mask_group_min_patches",
        "mask_group_max_patches",
        "mask_group_min_aspect_ratio",
        "mask_group_max_aspect_ratio",
        "return_codebook_pixels",
        "codebook_do_resize",
        "codebook_size",
        "int]]",
        "codebook_resample",
        "codebook_do_center_crop",
        "codebook_crop_size",
        "int]]",
        "codebook_do_rescale",
        "codebook_rescale_factor",
        "codebook_do_map_pixels",
        "codebook_do_normalize",
        "codebook_image_mean",
        "codebook_image_std",
        "return_tensors",
        "transformers.utils.generic.TensorType,",
        "NoneType]",
        "data_format",
        "<ChannelDimension.FIRST",
        "input_data_format",
        "transformers.image_utils.ChannelDimension,",
        "NoneType]"
    ],
    "params": [
        {
            "name": "images",
            "type": "ImageInput",
            "optional": false,
            "default": "",
            "description": "Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. Ifpassing in images with pixel values between 0 and 1, set do_rescale=False."
        },
        {
            "name": "do_resize",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to resize the image."
        },
        {
            "name": "size",
            "type": "Dict[str, int]",
            "optional": true,
            "default": "",
            "description": "Size of the image."
        },
        {
            "name": "resample",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Resampling filter to use if resizing the image. This can be one of the enum PILImageResampling, Onlyhas an effect if do_resize is set to True."
        },
        {
            "name": "do_center_crop",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to center crop the image."
        },
        {
            "name": "crop_size",
            "type": "Dict[str, int]",
            "optional": true,
            "default": "",
            "description": "Size of the center crop. Only has an effect if do_center_crop is set to True."
        },
        {
            "name": "do_rescale",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to rescale the image values between [0 - 1]."
        },
        {
            "name": "rescale_factor",
            "type": "float",
            "optional": true,
            "default": "",
            "description": "Rescale factor to rescale the image by if do_rescale is set to True."
        },
        {
            "name": "do_normalize",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to normalize the image."
        },
        {
            "name": "image_mean",
            "type": "float,List[float]",
            "optional": true,
            "default": "",
            "description": "Image mean."
        },
        {
            "name": "image_std",
            "type": "float,List[float]",
            "optional": true,
            "default": "",
            "description": "Image standard deviation."
        },
        {
            "name": "return_image_mask",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to return the image mask."
        },
        {
            "name": "input_size_patches",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Size of the patches to extract from the image."
        },
        {
            "name": "total_mask_patches",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Total number of patches to extract from the image."
        },
        {
            "name": "mask_group_min_patches",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Minimum number of patches to extract from the image."
        },
        {
            "name": "mask_group_max_patches",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Maximum number of patches to extract from the image."
        },
        {
            "name": "mask_group_min_aspect_ratio",
            "type": "float",
            "optional": true,
            "default": "",
            "description": "Minimum aspect ratio of the patches to extract from the image."
        },
        {
            "name": "mask_group_max_aspect_ratio",
            "type": "float",
            "optional": true,
            "default": "",
            "description": "Maximum aspect ratio of the patches to extract from the image."
        },
        {
            "name": "return_codebook_pixels",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to return the codebook pixels."
        },
        {
            "name": "codebook_do_resize",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to resize the codebook pixels."
        },
        {
            "name": "codebook_size",
            "type": "Dict[str, int]",
            "optional": true,
            "default": "",
            "description": "Size of the codebook pixels."
        },
        {
            "name": "codebook_resample",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Resampling filter to use if resizing the codebook pixels. This can be one of the enumPILImageResampling, Only has an effect if codebook_do_resize is set to True."
        },
        {
            "name": "codebook_do_center_crop",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to center crop the codebook pixels."
        },
        {
            "name": "codebook_crop_size",
            "type": "Dict[str, int]",
            "optional": true,
            "default": "",
            "description": "Size of the center crop of the codebook pixels. Only has an effect if codebook_do_center_crop is setto True."
        },
        {
            "name": "codebook_do_rescale",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to rescale the codebook pixels values between [0 - 1]."
        },
        {
            "name": "codebook_rescale_factor",
            "type": "float",
            "optional": true,
            "default": "",
            "description": "Rescale factor to rescale the codebook pixels by if codebook_do_rescale is set to True."
        },
        {
            "name": "codebook_do_map_pixels",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to map the codebook pixels values."
        },
        {
            "name": "codebook_do_normalize",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to normalize the codebook pixels."
        },
        {
            "name": "codebook_image_mean",
            "type": "float,List[float]",
            "optional": true,
            "default": "",
            "description": "Codebook pixels mean to normalize the codebook pixels by if codebook_do_normalize is set to True."
        },
        {
            "name": "codebook_image_std",
            "type": "float,List[float]",
            "optional": true,
            "default": "",
            "description": "Codebook pixels standard deviation to normalize the codebook pixels by if codebook_do_normalize isset to True."
        },
        {
            "name": "return_tensors",
            "type": "str,TensorType",
            "optional": true,
            "default": "",
            "description": "The type of tensors to return. Can be one of:Unset: Return a list of np.ndarray.TensorType.TENSORFLOW or tf: Return a batch of type tf.Tensor.TensorType.PYTORCH or pt: Return a batch of type torch.Tensor.TensorType.NUMPY or np: Return a batch of type np.ndarray.TensorType.JAX or jax: Return a batch of type jax.numpy.ndarray."
        },
        {
            "name": "data_format",
            "type": "ChannelDimension,str",
            "optional": true,
            "default": "",
            "description": "The channel dimension format for the output image. Can be one of:ChannelDimension.FIRST: image in (num_channels, height, width) format.ChannelDimension.LAST: image in (height, width, num_channels) format."
        },
        {
            "name": "input_data_format",
            "type": "ChannelDimension,str",
            "optional": true,
            "default": "",
            "description": "The channel dimension format for the input image. If unset, the channel dimension format is inferredfrom the input image. Can be one of:channels_first or ChannelDimension.FIRST: image in (num_channels, height, width) format.channels_last or ChannelDimension.LAST: image in (height, width, num_channels) format.none or ChannelDimension.NONE: image in (height, width) format."
        }
    ],
    "return": ""
}