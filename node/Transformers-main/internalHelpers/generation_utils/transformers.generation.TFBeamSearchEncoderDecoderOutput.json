{
    "api": "transformers.generation.TFBeamSearchEncoderDecoderOutput",
    "type": "class",
    "version": "main",
    "args_list": [
        "sequences:",
        "Tensor",
        "sequences_scores",
        "scores",
        "beam_indices",
        "encoder_attentions",
        "encoder_hidden_states",
        "decoder_attentions",
        "cross_attentions",
        "decoder_hidden_states"
    ],
    "params": [
        {
            "name": "sequences",
            "type": "tf.Tensor of shape (batch_size*num_return_sequences, sequence_length)",
            "optional": false,
            "default": "",
            "description": "The generated sequences. The second dimension (sequence_length) is either equal to max_length or shorterif all batches finished early due to the eos_token_id."
        },
        {
            "name": "sequences_scores",
            "type": "tf.Tensor of shape (batch_size*num_return_sequences",
            "optional": true,
            "default": "",
            "description": "Final beam scores of the generated sequences."
        },
        {
            "name": "scores",
            "type": "tuple(tf.Tensor) optional, returned when output_scores=True is passed,when config.output_scores=True",
            "optional": true,
            "default": "",
            "description": "Processed beam scores for each vocabulary token at each generation step. Beam scores consisting of logsoftmax scores for each vocabulary token and sum of log softmax of previously generated tokens in thisbeam. Tuple of tf.Tensorwith up tomax_new_tokenselements (one element for each generated token), with each tensor of shape(batch_size*num_beams, config.vocab_size)`."
        },
        {
            "name": "beam_indices",
            "type": "tf.Tensor",
            "optional": true,
            "default": "",
            "description": "Beam indices of generated token id at each generation step. tf.Tensor of shape(batch_size*num_return_sequences, sequence_length)."
        },
        {
            "name": "encoder_attentions",
            "type": "tuple(tf.Tensor",
            "optional": true,
            "default": "",
            "description": "Tuple of tf.Tensor (one for each layer of the decoder) of shape (batch_size, num_heads, sequence_length, sequence_length)."
        },
        {
            "name": "encoder_hidden_states",
            "type": "tuple(tf.Tensor",
            "optional": true,
            "default": "",
            "description": "Tuple of tf.Tensor (one for the output of the embeddings + one for the output of each layer) of shape(batch_size*num_beams*num_return_sequences, sequence_length, hidden_size)."
        },
        {
            "name": "decoder_attentions",
            "type": "tuple(tuple(tf.Tensor)",
            "optional": true,
            "default": "",
            "description": "Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) oftf.Tensor of shape (batch_size*num_beams*num_return_sequences, num_heads, generated_length, sequence_length)."
        },
        {
            "name": "cross_attentions",
            "type": "tuple(tuple(tf.Tensor)",
            "optional": true,
            "default": "",
            "description": "Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) oftf.Tensor of shape (batch_size, num_heads, generated_length, sequence_length)."
        },
        {
            "name": "decoder_hidden_states",
            "type": "tuple(tuple(tf.Tensor)",
            "optional": true,
            "default": "",
            "description": "Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) oftf.Tensor of shape (batch_size*num_beams*num_return_sequences, generated_length, hidden_size)."
        }
    ],
    "return": ""
}