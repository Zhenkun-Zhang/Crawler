{
    "api": "transformers.SwiftFormerConfig",
    "type": "class",
    "version": "main",
    "args_list": [
        "image_size",
        "num_channels",
        "depths",
        "3,",
        "6,",
        "4]",
        "embed_dims",
        "56,",
        "112,",
        "220]",
        "mlp_ratio",
        "downsamples",
        "True,",
        "True,",
        "True]",
        "hidden_act",
        "down_patch_size",
        "down_stride",
        "down_pad",
        "drop_path_rate",
        "drop_mlp_rate",
        "drop_conv_encoder_rate",
        "use_layer_scale",
        "layer_scale_init_value",
        "batch_norm_eps",
        "**kwargs"
    ],
    "params": [
        {
            "name": "image_size",
            "type": "int",
            "optional": true,
            "default": "224",
            "description": "The size (resolution) of each image"
        },
        {
            "name": "num_channels",
            "type": "int",
            "optional": true,
            "default": "3",
            "description": "The number of input channels"
        },
        {
            "name": "depths",
            "type": "List[int]",
            "optional": true,
            "default": "[3,",
            "description": "Depth of each stage"
        },
        {
            "name": "embed_dims",
            "type": "List[int]",
            "optional": true,
            "default": "[48,",
            "description": "The embedding dimension at each stage"
        },
        {
            "name": "mlp_ratio",
            "type": "int",
            "optional": true,
            "default": "4",
            "description": "Ratio of size of the hidden dimensionality of an MLP to the dimensionality of its input."
        },
        {
            "name": "downsamples",
            "type": "List[bool]",
            "optional": true,
            "default": "[True,",
            "description": "Whether or not to downsample inputs between two stages."
        },
        {
            "name": "hidden_act",
            "type": "str",
            "optional": true,
            "default": "gelu",
            "description": "The non-linear activation function (string). gelu, relu, selu and gelu_new are supported."
        },
        {
            "name": "down_patch_size",
            "type": "int",
            "optional": true,
            "default": "3",
            "description": "The size of patches in downsampling layers."
        },
        {
            "name": "down_stride",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "The stride of convolution kernels in downsampling layers."
        },
        {
            "name": "down_pad",
            "type": "int",
            "optional": true,
            "default": "1",
            "description": "Padding in downsampling layers."
        },
        {
            "name": "drop_path_rate",
            "type": "float",
            "optional": true,
            "default": "0.0",
            "description": "Rate at which to increase dropout probability in DropPath."
        },
        {
            "name": "drop_mlp_rate",
            "type": "float",
            "optional": true,
            "default": "0.0",
            "description": "Dropout rate for the MLP component of SwiftFormer."
        },
        {
            "name": "drop_conv_encoder_rate",
            "type": "float",
            "optional": true,
            "default": "0.0",
            "description": "Dropout rate for the ConvEncoder component of SwiftFormer."
        },
        {
            "name": "use_layer_scale",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether to scale outputs from token mixers."
        },
        {
            "name": "layer_scale_init_value",
            "type": "float",
            "optional": true,
            "default": "1e-05",
            "description": "Factor by which outputs from token mixers are scaled."
        },
        {
            "name": "batch_norm_eps",
            "type": "float",
            "optional": true,
            "default": "1e-05",
            "description": "The epsilon used by the batch normalization layers."
        }
    ],
    "return": ""
}