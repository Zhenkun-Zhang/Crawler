{
    "api": "transformers.AqlmConfig",
    "type": "class",
    "version": "main",
    "args_list": [
        "in_group_size:",
        "out_group_size",
        "num_codebooks",
        "nbits_per_codebook",
        "linear_weights_not_to_quantize",
        "**kwargs"
    ],
    "params": [
        {
            "name": "in_group_size",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "The group size along the input dimension."
        },
        {
            "name": "out_group_size",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "The group size along the output dimension. Its recommended to always use 1."
        },
        {
            "name": "num_codebooks",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Number of codebooks for the Additive Quantization procedure."
        },
        {
            "name": "nbits_per_codebook",
            "type": "int",
            "optional": true,
            "default": "",
            "description": "Number of bits encoding a single codebook vector. Codebooks size is 2**nbits_per_codebook."
        },
        {
            "name": "linear_weights_not_to_quantize",
            "type": "Optional[List[str]]",
            "optional": true,
            "default": "",
            "description": "List of full paths of nn.Linear weight parameters that shall not be quantized."
        },
        {
            "name": "kwargs",
            "type": "Dict[str, Any]",
            "optional": true,
            "default": "",
            "description": "Additional parameters from which to initialize the configuration object."
        }
    ],
    "return": ""
}