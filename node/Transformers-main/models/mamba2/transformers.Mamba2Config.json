{
    "api": "transformers.Mamba2Config",
    "type": "class",
    "version": "main",
    "args_list": [
        "num_heads",
        "head_dim",
        "vocab_size",
        "hidden_size",
        "state_size",
        "num_hidden_layers",
        "layer_norm_epsilon",
        "pad_token_id",
        "bos_token_id",
        "eos_token_id",
        "expand",
        "conv_kernel",
        "n_groups",
        "use_bias",
        "use_conv_bias",
        "hidden_act",
        "initializer_range",
        "residual_in_fp32",
        "time_step_rank",
        "time_step_min",
        "time_step_max",
        "time_step_floor",
        "time_step_limit",
        "inf)",
        "rescale_prenorm_residual",
        "use_cache",
        "rms_norm",
        "chunk_size",
        "tie_word_embeddings",
        "**kwargs"
    ],
    "params": [
        {
            "name": "num_heads",
            "type": "int",
            "optional": true,
            "default": "128",
            "description": "Number of heads for the evolution matrices of mamba 2."
        },
        {
            "name": "head_dim",
            "type": "int",
            "optional": true,
            "default": "64",
            "description": "Dimension of each head."
        },
        {
            "name": "vocab_size",
            "type": "int",
            "optional": true,
            "default": "32768",
            "description": "Vocabulary size of the MAMBA2 model. Defines the number of different tokens that can be represented by theinputs_ids passed when calling Mamba2Model."
        },
        {
            "name": "hidden_size",
            "type": "int",
            "optional": true,
            "default": "4096",
            "description": "Dimensionality of the embeddings and hidden states."
        },
        {
            "name": "state_size",
            "type": "int",
            "optional": true,
            "default": "128",
            "description": "shape of the state space latents."
        },
        {
            "name": "num_hidden_layers",
            "type": "int",
            "optional": true,
            "default": "64",
            "description": "Number of hidden layers in the model."
        },
        {
            "name": "layer_norm_epsilon",
            "type": "float",
            "optional": true,
            "default": "1e-05",
            "description": "The epsilon to use in the layer normalization layers."
        },
        {
            "name": "pad_token_id",
            "type": "int",
            "optional": true,
            "default": "1",
            "description": "Padding token id."
        },
        {
            "name": "bos_token_id",
            "type": "int",
            "optional": true,
            "default": "0",
            "description": "The id of the beginning of sentence token in the vocabulary."
        },
        {
            "name": "eos_token_id",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "The id of the end of sentence token in the vocabulary."
        },
        {
            "name": "expand",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "Expanding factor used to determine the intermediate size."
        },
        {
            "name": "conv_kernel",
            "type": "int",
            "optional": true,
            "default": "4",
            "description": "Size of the convolution kernel."
        },
        {
            "name": "n_groups",
            "type": "int",
            "optional": true,
            "default": "8",
            "description": "Number of groups for the evolution matrices of mamba 2."
        },
        {
            "name": "use_bias",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether or not to use bias in [in_proj, out_proj] of the mixer block"
        },
        {
            "name": "use_conv_bias",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not to use bias in the convolution layer of the mixer block."
        },
        {
            "name": "hidden_act",
            "type": "str",
            "optional": true,
            "default": "silu",
            "description": "The non-linear activation function (function or string) in the decoder."
        },
        {
            "name": "initializer_range",
            "type": "float",
            "optional": true,
            "default": "0.1",
            "description": "The standard deviation of the truncated_normal_initializer for initializing all weight matrices."
        },
        {
            "name": "residual_in_fp32",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not residuals should be in float32. If set to False residuals will keep the same dtype as the rest of the model"
        },
        {
            "name": "time_step_rank",
            "type": "Union[int,str]",
            "optional": true,
            "default": "auto",
            "description": "Rank of the discretization projection matrix. auto means that it will default to math.ceil(self.hidden_size / 16)"
        },
        {
            "name": "time_step_min",
            "type": "float",
            "optional": true,
            "default": "0.001",
            "description": "Minimum time_step used to bound dt_proj.bias."
        },
        {
            "name": "time_step_max",
            "type": "float",
            "optional": true,
            "default": "0.1",
            "description": "Maximum time_step used to bound dt_proj.bias."
        },
        {
            "name": "time_step_floor",
            "type": "float",
            "optional": true,
            "default": "0.0001",
            "description": "Minimum clamping value of the dt_proj.bias layer initialization."
        },
        {
            "name": "time_step_limit",
            "type": "tuple",
            "optional": true,
            "default": "(0.0,",
            "description": "Accepted range of time step values."
        },
        {
            "name": "rescale_prenorm_residual",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether or not to rescale out_proj weights when initializing."
        },
        {
            "name": "use_cache",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not the cache should be used."
        },
        {
            "name": "rms_norm",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether to use RMS norm or not."
        },
        {
            "name": "chunk_size",
            "type": "int",
            "optional": true,
            "default": "256",
            "description": "Size of the chunks that will comprise the sequence."
        },
        {
            "name": "tie_word_embeddings",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether to tie word embeddings or not."
        }
    ],
    "return": ""
}