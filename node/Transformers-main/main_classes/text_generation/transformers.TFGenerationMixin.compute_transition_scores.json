{
    "api": "transformers.TFGenerationMixin.compute_transition_scores",
    "type": "function",
    "version": "main",
    "args_list": [
        "sequences:",
        "Tensor",
        "scores",
        "beam_indices",
        "normalize_logits",
        ")"
    ],
    "params": [
        {
            "name": "sequences",
            "type": "tf.Tensor",
            "optional": false,
            "default": "",
            "description": "The generated sequences. The second dimension (sequence_length) is either equal to max_length orshorter if all batches finished early due to the eos_token_id."
        },
        {
            "name": "scores",
            "type": "tuple(tf.Tensor)",
            "optional": false,
            "default": "",
            "description": "Transition scores for each vocabulary token at each generation step. Beam transition scores consistingof log probabilities of tokens conditioned on log softmax of previously generated tokens Tuple oftf.Tensor with up to max_new_tokens elements (one element for each generated token), with eachtensor of shape (batch_size*num_beams, config.vocab_size)."
        },
        {
            "name": "beam_indices",
            "type": "tf.Tensor",
            "optional": true,
            "default": "",
            "description": "Beam indices of generated token id at each generation step. tf.Tensor of shape(batch_size*num_return_sequences, sequence_length). Only required if a num_beams>1 atgenerate-time."
        },
        {
            "name": "normalize_logits",
            "type": "bool",
            "optional": true,
            "default": "",
            "description": "Whether to normalize the logits (which, for legacy reasons, may be unnormalized)."
        }
    ],
    "return": "tf.Tensor"
}