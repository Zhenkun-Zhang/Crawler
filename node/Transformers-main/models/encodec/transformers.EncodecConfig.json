{
    "api": "transformers.EncodecConfig",
    "type": "class",
    "version": "main",
    "args_list": [
        "target_bandwidths",
        "3.0,",
        "6.0,",
        "12.0,",
        "24.0]",
        "sampling_rate",
        "audio_channels",
        "normalize",
        "chunk_length_s",
        "overlap",
        "hidden_size",
        "num_filters",
        "num_residual_layers",
        "upsampling_ratios",
        "5,",
        "4,",
        "2]",
        "norm_type",
        "kernel_size",
        "last_kernel_size",
        "residual_kernel_size",
        "dilation_growth_rate",
        "use_causal_conv",
        "pad_mode",
        "compress",
        "num_lstm_layers",
        "trim_right_ratio",
        "codebook_size",
        "codebook_dim",
        "use_conv_shortcut",
        "**kwargs"
    ],
    "params": [
        {
            "name": "target_bandwidths",
            "type": "List[float]",
            "optional": true,
            "default": "[1.5,",
            "description": "The range of diffent bandwiths the model can encode audio with."
        },
        {
            "name": "sampling_rate",
            "type": "int",
            "optional": true,
            "default": "24000",
            "description": "The sampling rate at which the audio waveform should be digitalized expressed in hertz (Hz)."
        },
        {
            "name": "audio_channels",
            "type": "int",
            "optional": true,
            "default": "1",
            "description": "Number of channels in the audio data. Either 1 for mono or 2 for stereo."
        },
        {
            "name": "normalize",
            "type": "bool",
            "optional": true,
            "default": "False",
            "description": "Whether the audio shall be normalized when passed."
        },
        {
            "name": "chunk_length_s",
            "type": "float",
            "optional": true,
            "default": "None",
            "description": "If defined the audio is pre-processed into chunks of lengths chunk_length_s and then encoded."
        },
        {
            "name": "overlap",
            "type": "float",
            "optional": true,
            "default": "None",
            "description": "Defines the overlap between each chunk. It is used to compute the chunk_stride using the followingformulae : int((1.0 - self.overlap) * self.chunk_length)."
        },
        {
            "name": "hidden_size",
            "type": "int",
            "optional": true,
            "default": "128",
            "description": "Intermediate representation dimension."
        },
        {
            "name": "num_filters",
            "type": "int",
            "optional": true,
            "default": "32",
            "description": "Number of convolution kernels of first EncodecConv1d down sampling layer."
        },
        {
            "name": "num_residual_layers",
            "type": "int,  optional, defaults to 1",
            "optional": true,
            "default": "1",
            "description": "Number of residual layers."
        },
        {
            "name": "upsampling_ratios",
            "type": "Sequence[int]",
            "optional": true,
            "default": "[8,",
            "description": "Kernel size and stride ratios. The encoder uses downsampling ratios instead of upsampling ratios, hence itwill use the ratios in the reverse order to the ones specified here that must match the decoder order."
        },
        {
            "name": "norm_type",
            "type": "str",
            "optional": true,
            "default": "weight_norm",
            "description": "Normalization method. Should be in [weight_norm, time_group_norm]"
        },
        {
            "name": "kernel_size",
            "type": "int",
            "optional": true,
            "default": "7",
            "description": "Kernel size for the initial convolution."
        },
        {
            "name": "last_kernel_size",
            "type": "int",
            "optional": true,
            "default": "7",
            "description": "Kernel size for the last convolution layer."
        },
        {
            "name": "residual_kernel_size",
            "type": "int",
            "optional": true,
            "default": "3",
            "description": "Kernel size for the residual layers."
        },
        {
            "name": "dilation_growth_rate",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "How much to increase the dilation with each layer."
        },
        {
            "name": "use_causal_conv",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether to use fully causal convolution."
        },
        {
            "name": "pad_mode",
            "type": "str",
            "optional": true,
            "default": "reflect",
            "description": "Padding mode for the convolutions."
        },
        {
            "name": "compress",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "Reduced dimensionality in residual branches (from Demucs v3)."
        },
        {
            "name": "num_lstm_layers",
            "type": "int",
            "optional": true,
            "default": "2",
            "description": "Number of LSTM layers at the end of the encoder."
        },
        {
            "name": "trim_right_ratio",
            "type": "float",
            "optional": true,
            "default": "1.0",
            "description": "Ratio for trimming at the right of the transposed convolution under the use_causal_conv = True setup. Ifequal to 1.0, it means that all the trimming is done at the right."
        },
        {
            "name": "codebook_size",
            "type": "int",
            "optional": true,
            "default": "1024",
            "description": "Number of discret codes that make up VQVAE."
        },
        {
            "name": "codebook_dim",
            "type": "int",
            "optional": true,
            "default": "None",
            "description": "Dimension of the codebook vectors. If not defined, uses hidden_size."
        },
        {
            "name": "use_conv_shortcut",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether to use a convolutional layer as the skip connection in the EncodecResnetBlock block. If False,an identity function will be used, giving a generic residual connection."
        }
    ],
    "return": ""
}