{
    "api": "transformers.UdopTokenizerFast",
    "type": "class",
    "version": "main",
    "args_list": [
        "vocab_file",
        "tokenizer_file",
        "eos_token",
        "sep_token",
        "unk_token",
        "pad_token",
        "sep_token_box",
        "1000,",
        "1000,",
        "1000]",
        "pad_token_box",
        "0,",
        "0,",
        "0]",
        "pad_token_label",
        "only_label_first_subword",
        "additional_special_tokens",
        "**kwargs"
    ],
    "params": [
        {
            "name": "vocab_file",
            "type": "str",
            "optional": true,
            "default": "None",
            "description": "Path to the vocabulary file."
        },
        {
            "name": "tokenizer_file",
            "type": "str",
            "optional": true,
            "default": "None",
            "description": "Path to the tokenizer file."
        },
        {
            "name": "eos_token",
            "type": "str",
            "optional": true,
            "default": "</s>",
            "description": "The end of sequence token.When building a sequence using special tokens, this is not the token that is used for the end of sequence.The token used is the sep_token."
        },
        {
            "name": "sep_token",
            "type": "str",
            "optional": true,
            "default": "</s>",
            "description": "The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences forsequence classification or for a text and a question for question answering. It is also used as the lasttoken of a sequence built with special tokens."
        },
        {
            "name": "unk_token",
            "type": "str",
            "optional": true,
            "default": "<unk>",
            "description": "The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be thistoken instead."
        },
        {
            "name": "pad_token",
            "type": "str",
            "optional": true,
            "default": "<pad>",
            "description": "The token used for padding, for example when batching sequences of different lengths."
        },
        {
            "name": "sep_token_box",
            "type": "List[int]",
            "optional": true,
            "default": "[1000,",
            "description": "The bounding box to use for the special [SEP] token."
        },
        {
            "name": "pad_token_box",
            "type": "List[int]",
            "optional": true,
            "default": "[0,",
            "description": "The bounding box to use for the special [PAD] token."
        },
        {
            "name": "pad_token_label",
            "type": "int",
            "optional": true,
            "default": "-100",
            "description": "The label to use for padding tokens. Defaults to -100, which is the ignore_index of PyTorchsCrossEntropyLoss."
        },
        {
            "name": "only_label_first_subword",
            "type": "bool",
            "optional": true,
            "default": "True",
            "description": "Whether or not to only label the first subword, in case word labels are provided."
        },
        {
            "name": "additional_special_tokens",
            "type": "List[str]",
            "optional": true,
            "default": "None",
            "description": "Additional special tokens used by the tokenizer."
        }
    ],
    "return": ""
}