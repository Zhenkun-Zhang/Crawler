{
    "api": "transformers.LayoutLMv2Tokenizer",
    "type": "class",
    "version": "main",
    "args_list": [
        "vocab_file",
        "do_lower_case",
        "do_basic_tokenize",
        "never_split",
        "unk_token",
        "sep_token",
        "pad_token",
        "cls_token",
        "mask_token",
        "cls_token_box",
        "0,",
        "0,",
        "0]",
        "sep_token_box",
        "1000,",
        "1000,",
        "1000]",
        "pad_token_box",
        "0,",
        "0,",
        "0]",
        "pad_token_label",
        "only_label_first_subword",
        "tokenize_chinese_chars",
        "strip_accents",
        "model_max_length",
        "additional_special_tokens",
        "**kwargs"
    ],
    "params": [],
    "return": ""
}